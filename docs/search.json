[
  {
    "objectID": "5.resampling.html",
    "href": "5.resampling.html",
    "title": "Chapter 5: Resampling Methods",
    "section": "",
    "text": "cross-validation\nbootstrap\n\n\n\n\n\nSplit data into the following two sets\n\na training set\na validation set (hold-out set)\n\nWe can estimate the test error rate from the validation set error rate, which can be highly variable.\n\n\n\nLOOCV addresses the high variability of the validation set approach.\nWith least squares linear or polynomial regression, the cost of LOOCV is the same as that of a single model.\n\n\n\n\nIt randomly divides the set of observations into k groups.\n\nLOOCV is the special case of k-fold CV in which k is set to equal n.\n\nk-fold CV with k < n has a computational advantage to LOOCV.\nLOOCV reduces more bias than k-fold CV.\nLOOCV has higher variance than k-fold CV.\n\neach of n models is trained on an almost identical set of observations.\n\nk-fold CV often gives more accurate estimates of the test error rate than LOOCV.\n\nSo typically, k = 5 or k = 10 tends to yield more accurate test error rate estimates.\n\n\n\n\n\\[Err_i = I(y_i \\neq \\hat{y_i})\\]\n\n\n\n\nit is used to quantify the uncertainty associated with a given estimator.\nE.g., the bootstrap can be used to estimate the standard errors of the coefficients.\n\n\n\n\n\n\n\nlibrary(ISLR2)\nset.seed(1)\ntrain = sample(392, 196)\n\nSimple Linear Regression Model:\n\nlm.fit = lm(mpg ~ horsepower, data = Auto, subset = train)\n\n\nattach(Auto)\nmean((mpg - predict(lm.fit, Auto))[-train]^2) # the estimated test MSE\n\n[1] 23.26601\n\n\npolynomial regression models:\n\nlm.fit2 = lm(mpg ~ poly(horsepower, 2), data = Auto, subset = train)\nmean((mpg - predict(lm.fit2, Auto))[-train]^2) # the estimated test MSE\n\n[1] 18.71646\n\n\n\nlm.fit3 = lm(mpg ~ poly(horsepower, 3), data = Auto, subset = train)\nmean((mpg - predict(lm.fit3, Auto))[-train]^2) # the estimated test MSE\n\n[1] 18.79401\n\n\nWe prefer the quadratic regression model based on the validation MSE.\n\n\n\n\nglm.fit = glm(mpg ~ horsepower, data = Auto)\ncoef(glm.fit)\n\n(Intercept)  horsepower \n 39.9358610  -0.1578447 \n\n\n\nlibrary(boot)\ncv.err = cv.glm(Auto, glm.fit)\ncv.err$delta # [1]: the standard k-fold CV estimate, [2]: a bias-corrected version\n\n[1] 24.23151 24.23114\n\n\n\ncv.error = rep(0, 10)\nfor(i in 1:10){\n  glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)\n  cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]\n}\ncv.error\n\n [1] 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115\n [9] 19.06863 19.49093\n\n\n\nplot(cv.error)\n\n\n\n\nWe see a sharp drop in the estimated test MSE between the linear and quadratic fits, while not from higher-order polynomials.\n\n\n\n\nset.seed(17)\ncv.error.10 = rep(0, 10)\nfor (i in 1:10) {\n  glm.fit = glm(mpg ~ poly(horsepower, i), data = Auto)\n  cv.error.10[i] = cv.glm(Auto, glm.fit, K = 10)$delta[1]\n}\ncv.error.10\n\n [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666\n [9] 18.87013 20.95520\n\n\n\nplot(cv.error.10)\n\n\n\n\nHigher-order polynomials than quadratic does not show improvement of test MSE.\n\n\n\n\nhead(Portfolio)\n\n           X          Y\n1 -0.8952509 -0.2349235\n2 -1.5624543 -0.8851760\n3 -0.4170899  0.2718880\n4  1.0443557 -0.7341975\n5 -0.3155684  0.8419834\n6 -1.7371238 -2.0371910\n\n\n\nalpha.fn = function(data, index){\n  X = data$X[index]\n  Y = data$Y[index]\n  (var(Y) - cov(X, Y) / (var(X) + var(Y) - 2 * cov(X, Y)))\n}\n\n\nalpha.fn(Portfolio, 1:100)\n\n[1] 0.7792916\n\n\n\nset.seed(7)\nalpha.fn(Portfolio, sample(100, 100, replace = T))\n\n[1] 0.9142495\n\n\n\nboot(Portfolio, alpha.fn, R = 1000)\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = Portfolio, statistic = alpha.fn, R = 1000)\n\n\nBootstrap Statistics :\n     original      bias    std. error\nt1* 0.7792916 -0.02651568   0.1723508\n\n\n\nboot.fn = function(data, index){\n  coef(lm(mpg ~ horsepower, data= data, subset = index))\n}\n\n\nboot.fn(Auto, 1:392)\n\n(Intercept)  horsepower \n 39.9358610  -0.1578447 \n\n\n\nset.seed(1)\nboot.fn(Auto, sample(392, 392, replace = T))\n\n(Intercept)  horsepower \n 40.3404517  -0.1634868 \n\n\n\nboot(Auto, boot.fn, 1000)\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = Auto, statistic = boot.fn, R = 1000)\n\n\nBootstrap Statistics :\n      original        bias    std. error\nt1* 39.9358610  0.0549915227 0.841925746\nt2* -0.1578447 -0.0006210818 0.007348956\n\n\n\nsummary(lm(mpg ~ horsepower , data = Auto))$coef\n\n              Estimate  Std. Error   t value      Pr(>|t|)\n(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\nhorsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81\n\n\n\nboot.fn2 = function(data, index){\n  coef(lm(mpg ~ horsepower + I(horsepower^2), data= data, subset = index))\n}\n\n\nset.seed(1)\nboot(Auto, boot.fn2, 1000)\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = Auto, statistic = boot.fn2, R = 1000)\n\n\nBootstrap Statistics :\n        original        bias     std. error\nt1* 56.900099702  3.511640e-02 2.0300222526\nt2* -0.466189630 -7.080834e-04 0.0324241984\nt3*  0.001230536  2.840324e-06 0.0001172164\n\n\n\nsummary(lm(mpg ~ horsepower + I(horsepower^2), data = Auto))\n\n\nCall:\nlm(formula = mpg ~ horsepower + I(horsepower^2), data = Auto)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.7135  -2.5943  -0.0859   2.2868  15.8961 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     56.9000997  1.8004268   31.60   <2e-16 ***\nhorsepower      -0.4661896  0.0311246  -14.98   <2e-16 ***\nI(horsepower^2)  0.0012305  0.0001221   10.08   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.374 on 389 degrees of freedom\nMultiple R-squared:  0.6876,    Adjusted R-squared:  0.686 \nF-statistic:   428 on 2 and 389 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "isl_web",
    "section": "",
    "text": "To learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  }
]